{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text = ['Introduction to NLP','It is likely to be useful, to people','Machine Learning is the new electrcity',\n       'R is good language','I Like this book','I want more books like this']",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.DataFrame({'tweet':text})\nprint(df)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                                    tweet\n0                     Introduction to NLP\n1    It is likely to be useful, to people\n2  Machine Learning is the new electrcity\n3                      R is good language\n4                        I Like this book\n5             I want more books like this\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install -U textblob",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting textblob\n  Using cached https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl\nRequirement already satisfied, skipping upgrade: nltk>=3.1 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from textblob) (3.4.5)\nRequirement already satisfied, skipping upgrade: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.11.0)\n\u001b[31mERROR: scrubadub 1.2.0 has requirement textblob==0.10.0, but you'll have textblob 0.15.3 which is incompatible.\u001b[0m\nInstalling collected packages: textblob\n  Found existing installation: textblob 0.10.0\n    Uninstalling textblob-0.10.0:\n      Successfully uninstalled textblob-0.10.0\nSuccessfully installed textblob-0.15.3\n\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade pip",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting pip\n  Using cached https://files.pythonhosted.org/packages/30/db/9e38760b32e3e7f40cce46dd5fb107b8c73840df38f0046d8e6514e675a1/pip-19.2.3-py2.py3-none-any.whl\nInstalling collected packages: pip\n  Found existing installation: pip 19.2.2\n    Uninstalling pip-19.2.2:\n      Successfully uninstalled pip-19.2.2\nSuccessfully installed pip-19.2.3\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!python -m textblob.download_corpora",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package brown to /home/nbuser/nltk_data...\n[nltk_data]   Package brown is already up-to-date!\n[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /home/nbuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/nbuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package conll2000 to /home/nbuser/nltk_data...\n[nltk_data]   Package conll2000 is already up-to-date!\n[nltk_data] Downloading package movie_reviews to\n[nltk_data]     /home/nbuser/nltk_data...\n[nltk_data]   Package movie_reviews is already up-to-date!\nFinished.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from textblob import TextBlob     #here TextBlob is class and textblob is the package\ndf['tweet'].apply(lambda x: str(TextBlob(x).correct()))\n\n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "0                        Introduction to NLP\n1       It is likely to be useful, to people\n2    Machine Learning is the new electricity\n3                         R is good language\n4                           I Like this book\n5                I want more books like this\nName: tweet, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['tweet']",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "0                       Introduction to NLP\n1      It is likely to be useful, to people\n2    Machine Learning is the new electrcity\n3                        R is good language\n4                          I Like this book\n5               I want more books like this\nName: tweet, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "help('textblob')",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Help on package textblob:\n\nNAME\n    textblob\n\nPACKAGE CONTENTS\n    _text\n    base\n    blob\n    classifiers\n    compat\n    decorators\n    download_corpora\n    en (package)\n    exceptions\n    formats\n    inflect\n    mixins\n    np_extractors\n    parsers\n    sentiments\n    taggers\n    tokenizers\n    translate\n    unicodecsv (package)\n    utils\n    wordnet\n\nCLASSES\n    builtins.list(builtins.object)\n        textblob.blob.WordList\n    builtins.object\n        textblob.blob.Blobber\n    builtins.str(builtins.object)\n        textblob.blob.Word\n    textblob.blob.BaseBlob(textblob.mixins.StringlikeMixin, textblob.mixins.BlobComparableMixin)\n        textblob.blob.Sentence\n        textblob.blob.TextBlob\n    \n    class Blobber(builtins.object)\n     |  A factory for TextBlobs that all share the same tagger,\n     |  tokenizer, parser, classifier, and np_extractor.\n     |  \n     |  Usage:\n     |  \n     |      >>> from textblob import Blobber\n     |      >>> from textblob.taggers import NLTKTagger\n     |      >>> from textblob.tokenizers import SentenceTokenizer\n     |      >>> tb = Blobber(pos_tagger=NLTKTagger(), tokenizer=SentenceTokenizer())\n     |      >>> blob1 = tb(\"This is one blob.\")\n     |      >>> blob2 = tb(\"This blob has the same tagger and tokenizer.\")\n     |      >>> blob1.pos_tagger is blob2.pos_tagger\n     |      True\n     |  \n     |  :param tokenizer: (optional) A tokenizer instance. If ``None``,\n     |      defaults to :class:`WordTokenizer() <textblob.tokenizers.WordTokenizer>`.\n     |  :param np_extractor: (optional) An NPExtractor instance. If ``None``,\n     |      defaults to :class:`FastNPExtractor() <textblob.en.np_extractors.FastNPExtractor>`.\n     |  :param pos_tagger: (optional) A Tagger instance. If ``None``,\n     |      defaults to :class:`NLTKTagger <textblob.en.taggers.NLTKTagger>`.\n     |  :param analyzer: (optional) A sentiment analyzer. If ``None``,\n     |      defaults to :class:`PatternAnalyzer <textblob.en.sentiments.PatternAnalyzer>`.\n     |  :param parser: A parser. If ``None``, defaults to\n     |      :class:`PatternParser <textblob.en.parsers.PatternParser>`.\n     |  :param classifier: A classifier.\n     |  \n     |  .. versionadded:: 0.4.0\n     |  \n     |  Methods defined here:\n     |  \n     |  __call__(self, text)\n     |      Return a new TextBlob object with this Blobber's ``np_extractor``,\n     |      ``pos_tagger``, ``tokenizer``, ``analyzer``, and ``classifier``.\n     |      \n     |      :returns: A new :class:`TextBlob <TextBlob>`.\n     |  \n     |  __init__(self, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None)\n     |      Initialize self.  See help(type(self)) for accurate signature.\n     |  \n     |  __repr__(self)\n     |      Return repr(self).\n     |  \n     |  __str__ = __repr__(self)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  __dict__\n     |      dictionary for instance variables (if defined)\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data and other attributes defined here:\n     |  \n     |  analyzer = <textblob.en.sentiments.PatternAnalyzer object>\n     |  \n     |  np_extractor = <textblob.en.np_extractors.FastNPExtractor object>\n     |  \n     |  parser = <textblob.en.parsers.PatternParser object>\n     |  \n     |  pos_tagger = <textblob.en.taggers.NLTKTagger object>\n     |  \n     |  tokenizer = <textblob.tokenizers.WordTokenizer object>\n    \n    class Sentence(BaseBlob)\n     |  A sentence within a TextBlob. Inherits from :class:`BaseBlob <BaseBlob>`.\n     |  \n     |  :param sentence: A string, the raw sentence.\n     |  :param start_index: An int, the index where this sentence begins\n     |                      in a TextBlob. If not given, defaults to 0.\n     |  :param end_index: An int, the index where this sentence ends in\n     |                      a TextBlob. If not given, defaults to the\n     |                      length of the sentence - 1.\n     |  \n     |  Method resolution order:\n     |      Sentence\n     |      BaseBlob\n     |      textblob.mixins.StringlikeMixin\n     |      textblob.mixins.BlobComparableMixin\n     |      textblob.mixins.ComparableMixin\n     |      builtins.object\n     |  \n     |  Methods defined here:\n     |  \n     |  __init__(self, sentence, start_index=0, end_index=None, *args, **kwargs)\n     |      Initialize self.  See help(type(self)) for accurate signature.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  dict\n     |      The dict representation of this sentence.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from BaseBlob:\n     |  \n     |  __add__(self, other)\n     |      Concatenates two text objects the same way Python strings are\n     |      concatenated.\n     |      \n     |      Arguments:\n     |      - `other`: a string or a text object\n     |  \n     |  __hash__(self)\n     |      Return hash(self).\n     |  \n     |  classify(self)\n     |      Classify the blob using the blob's ``classifier``.\n     |  \n     |  correct(self)\n     |      Attempt to correct the spelling of a blob.\n     |      \n     |      .. versionadded:: 0.6.0\n     |      \n     |      :rtype: :class:`BaseBlob <BaseBlob>`\n     |  \n     |  detect_language(self)\n     |      Detect the blob's language using the Google Translate API.\n     |      \n     |      Requires an internet connection.\n     |      \n     |      Usage:\n     |      ::\n     |      \n     |          >>> b = TextBlob(\"bonjour\")\n     |          >>> b.detect_language()\n     |          u'fr'\n     |      \n     |      Language code reference:\n     |          https://developers.google.com/translate/v2/using_rest#language-params\n     |      \n     |      .. versionadded:: 0.5.0\n     |      \n     |      :rtype: str\n     |  \n     |  ngrams(self, n=3)\n     |      Return a list of n-grams (tuples of n successive words) for this\n     |      blob.\n     |      \n     |      :rtype: List of :class:`WordLists <WordList>`\n     |  \n     |  noun_phrases = <textblob.decorators.cached_property object>\n     |  np_counts = <textblob.decorators.cached_property object>\n     |  parse(self, parser=None)\n     |      Parse the text.\n     |      \n     |      :param parser: (optional) A parser instance. If ``None``, defaults to\n     |          this blob's default parser.\n     |      \n     |      .. versionadded:: 0.6.0\n     |  \n     |  polarity = <textblob.decorators.cached_property object>\n     |  pos_tags = <textblob.decorators.cached_property object>\n     |  sentiment = <textblob.decorators.cached_property object>\n     |  sentiment_assessments = <textblob.decorators.cached_property object>\n     |  split(self, sep=None, maxsplit=9223372036854775807)\n     |      Behaves like the built-in str.split() except returns a\n     |      WordList.\n     |      \n     |      :rtype: :class:`WordList <WordList>`\n     |  \n     |  subjectivity = <textblob.decorators.cached_property object>\n     |  tags = <textblob.decorators.cached_property object>\n     |  tokenize(self, tokenizer=None)\n     |      Return a list of tokens, using ``tokenizer``.\n     |      \n     |      :param tokenizer: (optional) A tokenizer object. If None, defaults to\n     |          this blob's default tokenizer.\n     |  \n     |  tokens = <textblob.decorators.cached_property object>\n     |  translate(self, from_lang='auto', to='en')\n     |      Translate the blob to another language.\n     |      Uses the Google Translate API. Returns a new TextBlob.\n     |      \n     |      Requires an internet connection.\n     |      \n     |      Usage:\n     |      ::\n     |      \n     |          >>> b = TextBlob(\"Simple is better than complex\")\n     |          >>> b.translate(to=\"es\")\n     |          TextBlob('Lo simple es mejor que complejo')\n     |      \n     |      Language code reference:\n     |          https://developers.google.com/translate/v2/using_rest#language-params\n     |      \n     |      .. versionadded:: 0.5.0.\n     |      \n     |      :param str from_lang: Language to translate from. If ``None``, will attempt\n     |          to detect the language.\n     |      :param str to: Language to translate to.\n     |      :rtype: :class:`BaseBlob <BaseBlob>`\n     |  \n     |  word_counts = <textblob.decorators.cached_property object>\n     |  words = <textblob.decorators.cached_property object>\n     |  ----------------------------------------------------------------------\n     |  Data and other attributes inherited from BaseBlob:\n     |  \n     |  analyzer = <textblob.en.sentiments.PatternAnalyzer object>\n     |  \n     |  np_extractor = <textblob.en.np_extractors.FastNPExtractor object>\n     |  \n     |  parser = <textblob.en.parsers.PatternParser object>\n     |  \n     |  pos_tagger = <textblob.en.taggers.NLTKTagger object>\n     |  \n     |  tokenizer = <textblob.tokenizers.WordTokenizer object>\n     |  \n     |  translator = <textblob.translate.Translator object>\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from textblob.mixins.StringlikeMixin:\n     |  \n     |  __contains__(self, sub)\n     |      Implements the `in` keyword like a Python string.\n     |  \n     |  __getitem__(self, index)\n     |      Returns a  substring. If index is an integer, returns a Python\n     |      string of a single character. If a range is given, e.g. `blob[3:5]`,\n     |      a new instance of the class is returned.\n     |  \n     |  __iter__(self)\n     |      Makes the object iterable as if it were a string,\n     |      iterating through the raw string's characters.\n     |  \n     |  __len__(self)\n     |      Returns the length of the raw text.\n     |  \n     |  __repr__(self)\n     |      Returns a string representation for debugging.\n     |  \n     |  __str__(self)\n     |      Returns a string representation used in print statements\n     |      or str(my_blob).\n     |  \n     |  ends_with = endswith(self, suffix, start=0, end=9223372036854775807)\n     |      Returns True if the blob ends with the given suffix.\n     |  \n     |  endswith(self, suffix, start=0, end=9223372036854775807)\n     |      Returns True if the blob ends with the given suffix.\n     |  \n     |  find(self, sub, start=0, end=9223372036854775807)\n     |      Behaves like the built-in str.find() method. Returns an integer,\n     |      the index of the first occurrence of the substring argument sub in the\n     |      sub-string given by [start:end].\n     |  \n     |  format(self, *args, **kwargs)\n     |      Perform a string formatting operation, like the built-in\n     |      `str.format(*args, **kwargs)`. Returns a blob object.\n     |  \n     |  index(self, sub, start=0, end=9223372036854775807)\n     |      Like blob.find() but raise ValueError when the substring\n     |      is not found.\n     |  \n     |  join(self, iterable)\n     |      Behaves like the built-in `str.join(iterable)` method, except\n     |      returns a blob object.\n     |      \n     |      Returns a blob which is the concatenation of the strings or blobs\n     |      in the iterable.\n     |  \n     |  lower(self)\n     |      Like str.lower(), returns new object with all lower-cased characters.\n     |  \n     |  replace(self, old, new, count=9223372036854775807)\n     |      Return a new blob object with all the occurence of `old` replaced\n     |      by `new`.\n     |  \n     |  rfind(self, sub, start=0, end=9223372036854775807)\n     |      Behaves like the built-in str.rfind() method. Returns an integer,\n     |      the index of he last (right-most) occurence of the substring argument\n     |      sub in the sub-sequence given by [start:end].\n     |  \n     |  rindex(self, sub, start=0, end=9223372036854775807)\n     |      Like blob.rfind() but raise ValueError when substring is not\n     |      found.\n     |  \n     |  starts_with = startswith(self, prefix, start=0, end=9223372036854775807)\n     |      Returns True if the blob starts with the given prefix.\n     |  \n     |  startswith(self, prefix, start=0, end=9223372036854775807)\n     |      Returns True if the blob starts with the given prefix.\n     |  \n     |  strip(self, chars=None)\n     |      Behaves like the built-in str.strip([chars]) method. Returns\n     |      an object with leading and trailing whitespace removed.\n     |  \n     |  title(self)\n     |      Returns a blob object with the text in title-case.\n     |  \n     |  upper(self)\n     |      Like str.upper(), returns new object with all upper-cased characters.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors inherited from textblob.mixins.StringlikeMixin:\n     |  \n     |  __dict__\n     |      dictionary for instance variables (if defined)\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from textblob.mixins.ComparableMixin:\n     |  \n     |  __eq__(self, other)\n     |      Return self==value.\n     |  \n     |  __ge__(self, other)\n     |      Return self>=value.\n     |  \n     |  __gt__(self, other)\n     |      Return self>value.\n     |  \n     |  __le__(self, other)\n     |      Return self<=value.\n     |  \n     |  __lt__(self, other)\n     |      Return self<value.\n     |  \n     |  __ne__(self, other)\n     |      Return self!=value.\n    \n    class TextBlob(BaseBlob)\n     |  A general text block, meant for larger bodies of text (esp. those\n     |  containing sentences). Inherits from :class:`BaseBlob <BaseBlob>`.\n     |  \n     |  :param str text: A string.\n     |  :param tokenizer: (optional) A tokenizer instance. If ``None``, defaults to\n     |      :class:`WordTokenizer() <textblob.tokenizers.WordTokenizer>`.\n     |  :param np_extractor: (optional) An NPExtractor instance. If ``None``,\n     |      defaults to :class:`FastNPExtractor() <textblob.en.np_extractors.FastNPExtractor>`.\n     |  :param pos_tagger: (optional) A Tagger instance. If ``None``, defaults to\n     |      :class:`NLTKTagger <textblob.en.taggers.NLTKTagger>`.\n     |  :param analyzer: (optional) A sentiment analyzer. If ``None``, defaults to\n     |      :class:`PatternAnalyzer <textblob.en.sentiments.PatternAnalyzer>`.\n     |  :param classifier: (optional) A classifier.\n     |  \n     |  Method resolution order:\n     |      TextBlob\n     |      BaseBlob\n     |      textblob.mixins.StringlikeMixin\n     |      textblob.mixins.BlobComparableMixin\n     |      textblob.mixins.ComparableMixin\n     |      builtins.object\n     |  \n     |  Methods defined here:\n     |  \n     |  sentences = <textblob.decorators.cached_property object>\n     |  to_json(self, *args, **kwargs)\n     |      Return a json representation (str) of this blob.\n     |      Takes the same arguments as json.dumps.\n     |      \n     |      .. versionadded:: 0.5.1\n     |  \n     |  words = <textblob.decorators.cached_property object>\n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  json\n     |      The json representation of this blob.\n     |      \n     |      .. versionchanged:: 0.5.1\n     |          Made ``json`` a property instead of a method to restore backwards\n     |          compatibility that was broken after version 0.4.0.\n     |  \n     |  raw_sentences\n     |      List of strings, the raw sentences in the blob.\n     |  \n     |  serialized\n     |      Returns a list of each sentence's dict representation.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from BaseBlob:\n     |  \n     |  __add__(self, other)\n     |      Concatenates two text objects the same way Python strings are\n     |      concatenated.\n     |      \n     |      Arguments:\n     |      - `other`: a string or a text object\n     |  \n     |  __hash__(self)\n     |      Return hash(self).\n     |  \n     |  __init__(self, text, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None, clean_html=False)\n     |      Initialize self.  See help(type(self)) for accurate signature.\n     |  \n     |  classify(self)\n     |      Classify the blob using the blob's ``classifier``.\n     |  \n     |  correct(self)\n     |      Attempt to correct the spelling of a blob.\n     |      \n     |      .. versionadded:: 0.6.0\n     |      \n     |      :rtype: :class:`BaseBlob <BaseBlob>`\n     |  \n     |  detect_language(self)\n     |      Detect the blob's language using the Google Translate API.\n     |      \n     |      Requires an internet connection.\n     |      \n     |      Usage:\n     |      ::\n     |      \n     |          >>> b = TextBlob(\"bonjour\")\n     |          >>> b.detect_language()\n     |          u'fr'\n     |      \n     |      Language code reference:\n     |          https://developers.google.com/translate/v2/using_rest#language-params\n     |      \n     |      .. versionadded:: 0.5.0\n     |      \n     |      :rtype: str\n     |  \n     |  ngrams(self, n=3)\n     |      Return a list of n-grams (tuples of n successive words) for this\n     |      blob.\n     |      \n     |      :rtype: List of :class:`WordLists <WordList>`\n     |  \n     |  noun_phrases = <textblob.decorators.cached_property object>\n     |  np_counts = <textblob.decorators.cached_property object>\n     |  parse(self, parser=None)\n     |      Parse the text.\n     |      \n     |      :param parser: (optional) A parser instance. If ``None``, defaults to\n     |          this blob's default parser.\n     |      \n     |      .. versionadded:: 0.6.0\n     |  \n     |  polarity = <textblob.decorators.cached_property object>\n     |  pos_tags = <textblob.decorators.cached_property object>\n     |  sentiment = <textblob.decorators.cached_property object>\n     |  sentiment_assessments = <textblob.decorators.cached_property object>\n     |  split(self, sep=None, maxsplit=9223372036854775807)\n     |      Behaves like the built-in str.split() except returns a\n     |      WordList.\n     |      \n     |      :rtype: :class:`WordList <WordList>`\n     |  \n     |  subjectivity = <textblob.decorators.cached_property object>\n     |  tags = <textblob.decorators.cached_property object>\n     |  tokenize(self, tokenizer=None)\n     |      Return a list of tokens, using ``tokenizer``.\n     |      \n     |      :param tokenizer: (optional) A tokenizer object. If None, defaults to\n     |          this blob's default tokenizer.\n     |  \n     |  tokens = <textblob.decorators.cached_property object>\n     |  translate(self, from_lang='auto', to='en')\n     |      Translate the blob to another language.\n     |      Uses the Google Translate API. Returns a new TextBlob.\n     |      \n     |      Requires an internet connection.\n     |      \n     |      Usage:\n     |      ::\n     |      \n     |          >>> b = TextBlob(\"Simple is better than complex\")\n     |          >>> b.translate(to=\"es\")\n     |          TextBlob('Lo simple es mejor que complejo')\n     |      \n     |      Language code reference:\n     |          https://developers.google.com/translate/v2/using_rest#language-params\n     |      \n     |      .. versionadded:: 0.5.0.\n     |      \n     |      :param str from_lang: Language to translate from. If ``None``, will attempt\n     |          to detect the language.\n     |      :param str to: Language to translate to.\n     |      :rtype: :class:`BaseBlob <BaseBlob>`\n     |  \n     |  word_counts = <textblob.decorators.cached_property object>\n     |  ----------------------------------------------------------------------\n     |  Data and other attributes inherited from BaseBlob:\n     |  \n     |  analyzer = <textblob.en.sentiments.PatternAnalyzer object>\n     |  \n     |  np_extractor = <textblob.en.np_extractors.FastNPExtractor object>\n     |  \n     |  parser = <textblob.en.parsers.PatternParser object>\n     |  \n     |  pos_tagger = <textblob.en.taggers.NLTKTagger object>\n     |  \n     |  tokenizer = <textblob.tokenizers.WordTokenizer object>\n     |  \n     |  translator = <textblob.translate.Translator object>\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from textblob.mixins.StringlikeMixin:\n     |  \n     |  __contains__(self, sub)\n     |      Implements the `in` keyword like a Python string.\n     |  \n     |  __getitem__(self, index)\n     |      Returns a  substring. If index is an integer, returns a Python\n     |      string of a single character. If a range is given, e.g. `blob[3:5]`,\n     |      a new instance of the class is returned.\n     |  \n     |  __iter__(self)\n     |      Makes the object iterable as if it were a string,\n     |      iterating through the raw string's characters.\n     |  \n     |  __len__(self)\n     |      Returns the length of the raw text.\n     |  \n     |  __repr__(self)\n     |      Returns a string representation for debugging.\n     |  \n     |  __str__(self)\n     |      Returns a string representation used in print statements\n     |      or str(my_blob).\n     |  \n     |  ends_with = endswith(self, suffix, start=0, end=9223372036854775807)\n     |      Returns True if the blob ends with the given suffix.\n     |  \n     |  endswith(self, suffix, start=0, end=9223372036854775807)\n     |      Returns True if the blob ends with the given suffix.\n     |  \n     |  find(self, sub, start=0, end=9223372036854775807)\n     |      Behaves like the built-in str.find() method. Returns an integer,\n     |      the index of the first occurrence of the substring argument sub in the\n     |      sub-string given by [start:end].\n     |  \n     |  format(self, *args, **kwargs)\n     |      Perform a string formatting operation, like the built-in\n     |      `str.format(*args, **kwargs)`. Returns a blob object.\n     |  \n     |  index(self, sub, start=0, end=9223372036854775807)\n     |      Like blob.find() but raise ValueError when the substring\n     |      is not found.\n     |  \n     |  join(self, iterable)\n     |      Behaves like the built-in `str.join(iterable)` method, except\n     |      returns a blob object.\n     |      \n     |      Returns a blob which is the concatenation of the strings or blobs\n     |      in the iterable.\n     |  \n     |  lower(self)\n     |      Like str.lower(), returns new object with all lower-cased characters.\n     |  \n     |  replace(self, old, new, count=9223372036854775807)\n     |      Return a new blob object with all the occurence of `old` replaced\n     |      by `new`.\n     |  \n     |  rfind(self, sub, start=0, end=9223372036854775807)\n     |      Behaves like the built-in str.rfind() method. Returns an integer,\n     |      the index of he last (right-most) occurence of the substring argument\n     |      sub in the sub-sequence given by [start:end].\n     |  \n     |  rindex(self, sub, start=0, end=9223372036854775807)\n     |      Like blob.rfind() but raise ValueError when substring is not\n     |      found.\n     |  \n     |  starts_with = startswith(self, prefix, start=0, end=9223372036854775807)\n     |      Returns True if the blob starts with the given prefix.\n     |  \n     |  startswith(self, prefix, start=0, end=9223372036854775807)\n     |      Returns True if the blob starts with the given prefix.\n     |  \n     |  strip(self, chars=None)\n     |      Behaves like the built-in str.strip([chars]) method. Returns\n     |      an object with leading and trailing whitespace removed.\n     |  \n     |  title(self)\n     |      Returns a blob object with the text in title-case.\n     |  \n     |  upper(self)\n     |      Like str.upper(), returns new object with all upper-cased characters.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors inherited from textblob.mixins.StringlikeMixin:\n     |  \n     |  __dict__\n     |      dictionary for instance variables (if defined)\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from textblob.mixins.ComparableMixin:\n     |  \n     |  __eq__(self, other)\n     |      Return self==value.\n     |  \n     |  __ge__(self, other)\n     |      Return self>=value.\n     |  \n     |  __gt__(self, other)\n     |      Return self>value.\n     |  \n     |  __le__(self, other)\n     |      Return self<=value.\n     |  \n     |  __lt__(self, other)\n     |      Return self<value.\n     |  \n     |  __ne__(self, other)\n     |      Return self!=value.\n    \n    class Word(builtins.str)\n     |  A simple word representation. Includes methods for inflection,\n     |  translation, and WordNet integration.\n     |  \n     |  Method resolution order:\n     |      Word\n     |      builtins.str\n     |      builtins.object\n     |  \n     |  Methods defined here:\n     |  \n     |  __init__(self, string, pos_tag=None)\n     |      Initialize self.  See help(type(self)) for accurate signature.\n     |  \n     |  __repr__(self)\n     |      Return repr(self).\n     |  \n     |  __str__(self)\n     |      Return str(self).\n     |  \n     |  correct(self)\n     |      Correct the spelling of the word. Returns the word with the highest\n     |      confidence using the spelling corrector.\n     |      \n     |      .. versionadded:: 0.6.0\n     |  \n     |  define(self, pos=None)\n     |      Return a list of definitions for this word. Each definition\n     |      corresponds to a synset for this word.\n     |      \n     |      :param pos: A part-of-speech tag to filter upon. If ``None``, definitions\n     |          for all parts of speech will be loaded.\n     |      :rtype: List of strings\n     |      \n     |      .. versionadded:: 0.7.0\n     |  \n     |  definitions = <textblob.decorators.cached_property object>\n     |  detect_language(self)\n     |      Detect the word's language using Google's Translate API.\n     |      \n     |      .. versionadded:: 0.5.0\n     |  \n     |  get_synsets(self, pos=None)\n     |      Return a list of Synset objects for this word.\n     |      \n     |      :param pos: A part-of-speech tag to filter upon. If ``None``, all\n     |          synsets for all parts of speech will be loaded.\n     |      \n     |      :rtype: list of Synsets\n     |      \n     |      .. versionadded:: 0.7.0\n     |  \n     |  lemma = <textblob.decorators.cached_property object>\n     |  lemmatize(self, pos=None)\n     |      Return the lemma for a word using WordNet's morphy function.\n     |      \n     |      :param pos: Part of speech to filter upon. If `None`, defaults to\n     |          ``_wordnet.NOUN``.\n     |      \n     |      .. versionadded:: 0.8.1\n     |  \n     |  pluralize(self)\n     |      Return the plural version of the word as a string.\n     |  \n     |  singularize(self)\n     |      Return the singular version of the word as a string.\n     |  \n     |  spellcheck(self)\n     |      Return a list of (word, confidence) tuples of spelling corrections.\n     |      \n     |      Based on: Peter Norvig, \"How to Write a Spelling Corrector\"\n     |      (http://norvig.com/spell-correct.html) as implemented in the pattern\n     |      library.\n     |      \n     |      .. versionadded:: 0.6.0\n     |  \n     |  stem(self, stemmer=<PorterStemmer>)\n     |      Stem a word using various NLTK stemmers. (Default: Porter Stemmer)\n     |      \n     |      .. versionadded:: 0.12.0\n     |  \n     |  synsets = <textblob.decorators.cached_property object>\n     |  translate(self, from_lang='auto', to='en')\n     |      Translate the word to another language using Google's\n     |      Translate API.\n     |      \n     |      .. versionadded:: 0.5.0\n     |  \n     |  ----------------------------------------------------------------------\n     |  Static methods defined here:\n     |  \n     |  __new__(cls, string, pos_tag=None)\n     |      Return a new instance of the class. It is necessary to override\n     |      this method in order to handle the extra pos_tag argument in the\n     |      constructor.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  __dict__\n     |      dictionary for instance variables (if defined)\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data and other attributes defined here:\n     |  \n     |  LancasterStemmer = <LancasterStemmer>\n     |  \n     |  PorterStemmer = <PorterStemmer>\n     |  \n     |  SnowballStemmer = <nltk.stem.snowball.SnowballStemmer object>\n     |  \n     |  translator = <textblob.translate.Translator object>\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from builtins.str:\n     |  \n     |  __add__(self, value, /)\n     |      Return self+value.\n     |  \n     |  __contains__(self, key, /)\n     |      Return key in self.\n     |  \n     |  __eq__(self, value, /)\n     |      Return self==value.\n     |  \n     |  __format__(...)\n     |      S.__format__(format_spec) -> str\n     |      \n     |      Return a formatted version of S as described by format_spec.\n     |  \n     |  __ge__(self, value, /)\n     |      Return self>=value.\n     |  \n     |  __getattribute__(self, name, /)\n     |      Return getattr(self, name).\n     |  \n     |  __getitem__(self, key, /)\n     |      Return self[key].\n     |  \n     |  __getnewargs__(...)\n     |  \n     |  __gt__(self, value, /)\n     |      Return self>value.\n     |  \n     |  __hash__(self, /)\n     |      Return hash(self).\n     |  \n     |  __iter__(self, /)\n     |      Implement iter(self).\n     |  \n     |  __le__(self, value, /)\n     |      Return self<=value.\n     |  \n     |  __len__(self, /)\n     |      Return len(self).\n     |  \n     |  __lt__(self, value, /)\n     |      Return self<value.\n     |  \n     |  __mod__(self, value, /)\n     |      Return self%value.\n     |  \n     |  __mul__(self, value, /)\n     |      Return self*value.\n     |  \n     |  __ne__(self, value, /)\n     |      Return self!=value.\n     |  \n     |  __rmod__(self, value, /)\n     |      Return value%self.\n     |  \n     |  __rmul__(self, value, /)\n     |      Return value*self.\n     |  \n     |  __sizeof__(...)\n     |      S.__sizeof__() -> size of S in memory, in bytes\n     |  \n     |  capitalize(...)\n     |      S.capitalize() -> str\n     |      \n     |      Return a capitalized version of S, i.e. make the first character\n     |      have upper case and the rest lower case.\n     |  \n     |  casefold(...)\n     |      S.casefold() -> str\n     |      \n     |      Return a version of S suitable for caseless comparisons.\n     |  \n     |  center(...)\n     |      S.center(width[, fillchar]) -> str\n     |      \n     |      Return S centered in a string of length width. Padding is\n     |      done using the specified fill character (default is a space)\n     |  \n     |  count(...)\n     |      S.count(sub[, start[, end]]) -> int\n     |      \n     |      Return the number of non-overlapping occurrences of substring sub in\n     |      string S[start:end].  Optional arguments start and end are\n     |      interpreted as in slice notation.\n     |  \n     |  encode(...)\n     |      S.encode(encoding='utf-8', errors='strict') -> bytes\n     |      \n     |      Encode S using the codec registered for encoding. Default encoding\n     |      is 'utf-8'. errors may be given to set a different error\n     |      handling scheme. Default is 'strict' meaning that encoding errors raise\n     |      a UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n     |      'xmlcharrefreplace' as well as any other name registered with\n     |      codecs.register_error that can handle UnicodeEncodeErrors.\n     |  \n     |  endswith(...)\n     |      S.endswith(suffix[, start[, end]]) -> bool\n     |      \n     |      Return True if S ends with the specified suffix, False otherwise.\n     |      With optional start, test S beginning at that position.\n     |      With optional end, stop comparing S at that position.\n     |      suffix can also be a tuple of strings to try.\n     |  \n     |  expandtabs(...)\n     |      S.expandtabs(tabsize=8) -> str\n     |      \n     |      Return a copy of S where all tab characters are expanded using spaces.\n     |      If tabsize is not given, a tab size of 8 characters is assumed.\n     |  \n     |  find(...)\n     |      S.find(sub[, start[, end]]) -> int\n     |      \n     |      Return the lowest index in S where substring sub is found,\n     |      such that sub is contained within S[start:end].  Optional\n     |      arguments start and end are interpreted as in slice notation.\n     |      \n     |      Return -1 on failure.\n     |  \n     |  format(...)\n     |      S.format(*args, **kwargs) -> str\n     |      \n     |      Return a formatted version of S, using substitutions from args and kwargs.\n     |      The substitutions are identified by braces ('{' and '}').\n     |  \n     |  format_map(...)\n     |      S.format_map(mapping) -> str\n     |      \n     |      Return a formatted version of S, using substitutions from mapping.\n     |      The substitutions are identified by braces ('{' and '}').\n     |  \n     |  index(...)\n     |      S.index(sub[, start[, end]]) -> int\n     |      \n     |      Return the lowest index in S where substring sub is found, \n     |      such that sub is contained within S[start:end].  Optional\n     |      arguments start and end are interpreted as in slice notation.\n     |      \n     |      Raises ValueError when the substring is not found.\n     |  \n     |  isalnum(...)\n     |      S.isalnum() -> bool\n     |      \n     |      Return True if all characters in S are alphanumeric\n     |      and there is at least one character in S, False otherwise.\n     |  \n     |  isalpha(...)\n     |      S.isalpha() -> bool\n     |      \n     |      Return True if all characters in S are alphabetic\n     |      and there is at least one character in S, False otherwise.\n     |  \n     |  isdecimal(...)\n     |      S.isdecimal() -> bool\n     |      \n     |      Return True if there are only decimal characters in S,\n     |      False otherwise.\n     |  \n     |  isdigit(...)\n     |      S.isdigit() -> bool\n     |      \n     |      Return True if all characters in S are digits\n     |      and there is at least one character in S, False otherwise.\n     |  \n     |  isidentifier(...)\n     |      S.isidentifier() -> bool\n     |      \n     |      Return True if S is a valid identifier according\n     |      to the language definition.\n     |      \n     |      Use keyword.iskeyword() to test for reserved identifiers\n     |      such as \"def\" and \"class\".\n     |  \n     |  islower(...)\n     |      S.islower() -> bool\n     |      \n     |      Return True if all cased characters in S are lowercase and there is\n     |      at least one cased character in S, False otherwise.\n     |  \n     |  isnumeric(...)\n     |      S.isnumeric() -> bool\n     |      \n     |      Return True if there are only numeric characters in S,\n     |      False otherwise.\n     |  \n     |  isprintable(...)\n     |      S.isprintable() -> bool\n     |      \n     |      Return True if all characters in S are considered\n     |      printable in repr() or S is empty, False otherwise.\n     |  \n     |  isspace(...)\n     |      S.isspace() -> bool\n     |      \n     |      Return True if all characters in S are whitespace\n     |      and there is at least one character in S, False otherwise.\n     |  \n     |  istitle(...)\n     |      S.istitle() -> bool\n     |      \n     |      Return True if S is a titlecased string and there is at least one\n     |      character in S, i.e. upper- and titlecase characters may only\n     |      follow uncased characters and lowercase characters only cased ones.\n     |      Return False otherwise.\n     |  \n     |  isupper(...)\n     |      S.isupper() -> bool\n     |      \n     |      Return True if all cased characters in S are uppercase and there is\n     |      at least one cased character in S, False otherwise.\n     |  \n     |  join(...)\n     |      S.join(iterable) -> str\n     |      \n     |      Return a string which is the concatenation of the strings in the\n     |      iterable.  The separator between elements is S.\n     |  \n     |  ljust(...)\n     |      S.ljust(width[, fillchar]) -> str\n     |      \n     |      Return S left-justified in a Unicode string of length width. Padding is\n     |      done using the specified fill character (default is a space).\n     |  \n     |  lower(...)\n     |      S.lower() -> str\n     |      \n     |      Return a copy of the string S converted to lowercase.\n     |  \n     |  lstrip(...)\n     |      S.lstrip([chars]) -> str\n     |      \n     |      Return a copy of the string S with leading whitespace removed.\n     |      If chars is given and not None, remove characters in chars instead.\n     |  \n     |  partition(...)\n     |      S.partition(sep) -> (head, sep, tail)\n     |      \n     |      Search for the separator sep in S, and return the part before it,\n     |      the separator itself, and the part after it.  If the separator is not\n     |      found, return S and two empty strings.\n     |  \n     |  replace(...)\n     |      S.replace(old, new[, count]) -> str\n     |      \n     |      Return a copy of S with all occurrences of substring\n     |      old replaced by new.  If the optional argument count is\n     |      given, only the first count occurrences are replaced.\n     |  \n     |  rfind(...)\n     |      S.rfind(sub[, start[, end]]) -> int\n     |      \n     |      Return the highest index in S where substring sub is found,\n     |      such that sub is contained within S[start:end].  Optional\n     |      arguments start and end are interpreted as in slice notation.\n     |      \n     |      Return -1 on failure.\n     |  \n     |  rindex(...)\n     |      S.rindex(sub[, start[, end]]) -> int\n     |      \n     |      Return the highest index in S where substring sub is found,\n     |      such that sub is contained within S[start:end].  Optional\n     |      arguments start and end are interpreted as in slice notation.\n     |      \n     |      Raises ValueError when the substring is not found.\n     |  \n     |  rjust(...)\n     |      S.rjust(width[, fillchar]) -> str\n     |      \n     |      Return S right-justified in a string of length width. Padding is\n     |      done using the specified fill character (default is a space).\n     |  \n     |  rpartition(...)\n     |      S.rpartition(sep) -> (head, sep, tail)\n     |      \n     |      Search for the separator sep in S, starting at the end of S, and return\n     |      the part before it, the separator itself, and the part after it.  If the\n     |      separator is not found, return two empty strings and S.\n     |  \n     |  rsplit(...)\n     |      S.rsplit(sep=None, maxsplit=-1) -> list of strings\n     |      \n     |      Return a list of the words in S, using sep as the\n     |      delimiter string, starting at the end of the string and\n     |      working to the front.  If maxsplit is given, at most maxsplit\n     |      splits are done. If sep is not specified, any whitespace string\n     |      is a separator.\n     |  \n     |  rstrip(...)\n     |      S.rstrip([chars]) -> str\n     |      \n     |      Return a copy of the string S with trailing whitespace removed.\n     |      If chars is given and not None, remove characters in chars instead.\n     |  \n     |  split(...)\n     |      S.split(sep=None, maxsplit=-1) -> list of strings\n     |      \n     |      Return a list of the words in S, using sep as the\n     |      delimiter string.  If maxsplit is given, at most maxsplit\n     |      splits are done. If sep is not specified or is None, any\n     |      whitespace string is a separator and empty strings are\n     |      removed from the result.\n     |  \n     |  splitlines(...)\n     |      S.splitlines([keepends]) -> list of strings\n     |      \n     |      Return a list of the lines in S, breaking at line boundaries.\n     |      Line breaks are not included in the resulting list unless keepends\n     |      is given and true.\n     |  \n     |  startswith(...)\n     |      S.startswith(prefix[, start[, end]]) -> bool\n     |      \n     |      Return True if S starts with the specified prefix, False otherwise.\n     |      With optional start, test S beginning at that position.\n     |      With optional end, stop comparing S at that position.\n     |      prefix can also be a tuple of strings to try.\n     |  \n     |  strip(...)\n     |      S.strip([chars]) -> str\n     |      \n     |      Return a copy of the string S with leading and trailing\n     |      whitespace removed.\n     |      If chars is given and not None, remove characters in chars instead.\n     |  \n     |  swapcase(...)\n     |      S.swapcase() -> str\n     |      \n     |      Return a copy of S with uppercase characters converted to lowercase\n     |      and vice versa.\n     |  \n     |  title(...)\n     |      S.title() -> str\n     |      \n     |      Return a titlecased version of S, i.e. words start with title case\n     |      characters, all remaining cased characters have lower case.\n     |  \n     |  upper(...)\n     |      S.upper() -> str\n     |      \n     |      Return a copy of S converted to uppercase.\n     |  \n     |  zfill(...)\n     |      S.zfill(width) -> str\n     |      \n     |      Pad a numeric string S with zeros on the left, to fill a field\n     |      of the specified width. The string S is never truncated.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Static methods inherited from builtins.str:\n     |  \n     |  maketrans(x, y=None, z=None, /)\n     |      Return a translation table usable for str.translate().\n     |      \n     |      If there is only one argument, it must be a dictionary mapping Unicode\n     |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n     |      Character keys will be then converted to ordinals.\n     |      If there are two arguments, they must be strings of equal length, and\n     |      in the resulting dictionary, each character in x will be mapped to the\n     |      character at the same position in y. If there is a third argument, it\n     |      must be a string, whose characters will be mapped to None in the result.\n    \n    class WordList(builtins.list)\n     |  A list-like collection of words.\n     |  \n     |  Method resolution order:\n     |      WordList\n     |      builtins.list\n     |      builtins.object\n     |  \n     |  Methods defined here:\n     |  \n     |  __getitem__(self, key)\n     |      Returns a string at the given index.\n     |  \n     |  __getslice__(self, i, j)\n     |  \n     |  __init__(self, collection)\n     |      Initialize a WordList. Takes a collection of strings as\n     |      its only argument.\n     |  \n     |  __repr__(self)\n     |      Returns a string representation for debugging.\n     |  \n     |  __setitem__(self, index, obj)\n     |      Places object at given index, replacing existing item. If the object\n     |      is a string, inserts a :class:`Word <Word>` object.\n     |  \n     |  __str__(self)\n     |      Returns a string representation for printing.\n     |  \n     |  append(self, obj)\n     |      Append an object to end. If the object is a string, appends a\n     |      :class:`Word <Word>` object.\n     |  \n     |  count(self, strg, case_sensitive=False, *args, **kwargs)\n     |      Get the count of a word or phrase `s` within this WordList.\n     |      \n     |      :param strg: The string to count.\n     |      :param case_sensitive: A boolean, whether or not the search is case-sensitive.\n     |  \n     |  extend(self, iterable)\n     |      Extend WordList by appending elements from ``iterable``. If an element\n     |      is a string, appends a :class:`Word <Word>` object.\n     |  \n     |  lemmatize(self)\n     |      Return the lemma of each word in this WordList.\n     |  \n     |  lower(self)\n     |      Return a new WordList with each word lower-cased.\n     |  \n     |  pluralize(self)\n     |      Return the plural version of each word in this WordList.\n     |  \n     |  singularize(self)\n     |      Return the single version of each word in this WordList.\n     |  \n     |  stem(self, *args, **kwargs)\n     |      Return the stem for each word in this WordList.\n     |  \n     |  upper(self)\n     |      Return a new WordList with each word upper-cased.\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data descriptors defined here:\n     |  \n     |  __dict__\n     |      dictionary for instance variables (if defined)\n     |  \n     |  __weakref__\n     |      list of weak references to the object (if defined)\n     |  \n     |  ----------------------------------------------------------------------\n     |  Methods inherited from builtins.list:\n     |  \n     |  __add__(self, value, /)\n     |      Return self+value.\n     |  \n     |  __contains__(self, key, /)\n     |      Return key in self.\n     |  \n     |  __delitem__(self, key, /)\n     |      Delete self[key].\n     |  \n     |  __eq__(self, value, /)\n     |      Return self==value.\n     |  \n     |  __ge__(self, value, /)\n     |      Return self>=value.\n     |  \n     |  __getattribute__(self, name, /)\n     |      Return getattr(self, name).\n     |  \n     |  __gt__(self, value, /)\n     |      Return self>value.\n     |  \n     |  __iadd__(self, value, /)\n     |      Implement self+=value.\n     |  \n     |  __imul__(self, value, /)\n     |      Implement self*=value.\n     |  \n     |  __iter__(self, /)\n     |      Implement iter(self).\n     |  \n     |  __le__(self, value, /)\n     |      Return self<=value.\n     |  \n     |  __len__(self, /)\n     |      Return len(self).\n     |  \n     |  __lt__(self, value, /)\n     |      Return self<value.\n     |  \n     |  __mul__(self, value, /)\n     |      Return self*value.\n     |  \n     |  __ne__(self, value, /)\n     |      Return self!=value.\n     |  \n     |  __new__(*args, **kwargs) from builtins.type\n     |      Create and return a new object.  See help(type) for accurate signature.\n     |  \n     |  __reversed__(...)\n     |      L.__reversed__() -- return a reverse iterator over the list\n     |  \n     |  __rmul__(self, value, /)\n     |      Return value*self.\n     |  \n     |  __sizeof__(...)\n     |      L.__sizeof__() -- size of L in memory, in bytes\n     |  \n     |  clear(...)\n     |      L.clear() -> None -- remove all items from L\n     |  \n     |  copy(...)\n     |      L.copy() -> list -- a shallow copy of L\n     |  \n     |  index(...)\n     |      L.index(value, [start, [stop]]) -> integer -- return first index of value.\n     |      Raises ValueError if the value is not present.\n     |  \n     |  insert(...)\n     |      L.insert(index, object) -- insert object before index\n     |  \n     |  pop(...)\n     |      L.pop([index]) -> item -- remove and return item at index (default last).\n     |      Raises IndexError if list is empty or index is out of range.\n     |  \n     |  remove(...)\n     |      L.remove(value) -> None -- remove first occurrence of value.\n     |      Raises ValueError if the value is not present.\n     |  \n     |  reverse(...)\n     |      L.reverse() -- reverse *IN PLACE*\n     |  \n     |  sort(...)\n     |      L.sort(key=None, reverse=False) -> None -- stable sort *IN PLACE*\n     |  \n     |  ----------------------------------------------------------------------\n     |  Data and other attributes inherited from builtins.list:\n     |  \n     |  __hash__ = None\n\nDATA\n    __all__ = ['TextBlob', 'Word', 'Sentence', 'Blobber', 'WordList']\n    __license__ = 'MIT'\n\nVERSION\n    0.15.3\n\nAUTHOR\n    Steven Loria\n\nFILE\n    /home/nbuser/anaconda3_501/lib/python3.6/site-packages/textblob/__init__.py\n\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#we can also used autocorrect library for spelling correction\n!pip install autocorrect==0.3.0",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting autocorrect==0.3.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/b6/6c74ff19249dc6d7285541cd59f5a3edbbd0f7209362a63e314fc09b2636/autocorrect-0.3.0.tar.gz (3.6MB)\n\u001b[K     || 3.6MB 2.6MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: autocorrect\n  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-0.3.0-cp35-none-any.whl size=3603077 sha256=413bc15035febd4fa65159fabb390139be10c181883b76ffe817e77ad7f19393\n  Stored in directory: /home/nbuser/.cache/pip/wheels/bf/b8/ae/704d5643f1d0637c5b87d9feccf2ee923c492b703bb0bfbb19\nSuccessfully built autocorrect\nInstalling collected packages: autocorrect\n  Found existing installation: autocorrect 0.3.1\n    Uninstalling autocorrect-0.3.1:\n      Successfully uninstalled autocorrect-0.3.1\nSuccessfully installed autocorrect-0.3.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from autocorrect import spell\nprint(spell('mussage'))\nprint(spell('suirvice'))",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "message\nservice\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "help('autocorrect')",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Help on package autocorrect:\n\nNAME\n    autocorrect - Spell function\n\nDESCRIPTION\n    Author: Jonas McCallum\n    https://github.com/foobarmus/autocorrect\n\nPACKAGE CONTENTS\n    nlp_parser\n    utils\n    word\n    word_lists\n\nFUNCTIONS\n    spell(word)\n        most likely correction for everything up to a double typo\n\nDATA\n    NLP_COUNTS = {'repeated': 207, 'accomplishments': 4, 'seceded...7, 'Pr...\n\nFILE\n    /home/nbuser/anaconda3_420/lib/python3.5/site-packages/autocorrect/__init__.py\n\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}